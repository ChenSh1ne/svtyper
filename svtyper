#!/usr/bin/env python

import pysam
import argparse, sys
import math, time, re
import multiprocessing
from collections import Counter
from argparse import RawTextHelpFormatter
from scipy.stats import norm

__author__ = "Colby Chiang (cc2qe@virginia.edu)"
__version__ = "$Revision: 0.0.1 $"
__date__ = "$Date: 2014-04-28 14:31 $"

# --------------------------------------
# define functions

def get_args():
    parser = argparse.ArgumentParser(formatter_class=RawTextHelpFormatter, description="\
svgt\n\
author: " + __author__ + "\n\
version: " + __version__ + "\n\
description: Compute genotype of structural variants based on breakpoint depth")
    parser.add_argument('-B', '--bam', type=pysam.Samfile, required=True, help='BAM file(s), comma-separated if genotyping multiple BAMs')
    parser.add_argument('-S', '--split_bam', type=pysam.Samfile, required=False, default=None, help='split-read bam file for sample')
    parser.add_argument('-v', '--input_vcf', type=argparse.FileType('r'), default=None, help='VCF input (default: stdin)')
    parser.add_argument('-o', '--output_vcf', type=argparse.FileType('w'), default=sys.stdout, help='output VCF to write (default: stdout)')
    parser.add_argument('-m', '--mean_frag_size', type=float, required=False, help='mean fragment size of library [auto]')
    parser.add_argument('-sd', '--sd_frag_size', type=float, required=False, help='standard deviation of fragment size of library [auto]')
    parser.add_argument('-f', '--splflank', type=int, required=False, default=20, help='min number of split read query bases flanking breakpoint on either side [20]')
    parser.add_argument('-F', '--discflank', type=int, required=False, default=20, help='min number of discordant read query bases flanking breakpoint on either side. (should not exceed read length) [20]')
    parser.add_argument('--split_weight', type=float, required=False, default=1, help='weight for split reads [1]')
    parser.add_argument('--disc_weight', type=float, required=False, default=1, help='weight for discordant paired-end reads [1]')
    parser.add_argument('-rl', '--read_length', type=int, required=False, help='maximum read-length in BAM [auto]')
    parser.add_argument('--debug', action='store_true', help='debugging verbosity')

    # parse the arguments
    args = parser.parse_args()

    # if no input, check if part of pipe and if so, read stdin.
    if args.input_vcf == None:
        if sys.stdin.isatty():
            parser.print_help()
            exit(1)
        else:
            args.input_vcf = sys.stdin
    # send back the user input
    return args

class Vcf(object):
    def __init__(self):
        self.file_format = 'VCFv4.2'
        # self.fasta = fasta
        self.reference = ''
        self.sample_list = []
        self.info_list = []
        self.format_list = []
        self.alt_list = []
        self.add_format('GT', 1, 'String', 'Genotype')

    def add_header(self, header):
        for line in header:
            if line.split('=')[0] == '##fileformat':
                self.file_format = line.rstrip().split('=')[1]
            elif line.split('=')[0] == '##reference':
                self.reference = line.rstrip().split('=')[1]
            elif line.split('=')[0] == '##INFO':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_info(*[b.split('=')[1] for b in r.findall(a)])
            elif line.split('=')[0] == '##ALT':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_alt(*[b.split('=')[1] for b in r.findall(a)])
            elif line.split('=')[0] == '##FORMAT':
                a = line[line.find('<')+1:line.find('>')]
                r = re.compile(r'(?:[^,\"]|\"[^\"]*\")+')
                self.add_format(*[b.split('=')[1] for b in r.findall(a)])
            elif line[0] == '#' and line[1] != '#':
                self.sample_list = line.rstrip().split('\t')[9:]

    # return the VCF header
    def get_header(self):
        header = '\n'.join(['##fileformat=' + self.file_format,
                            '##fileDate=' + time.strftime('%Y%m%d'),
                            '##reference=' + self.reference] + \
                           [i.hstring for i in self.info_list] + \
                           [a.hstring for a in self.alt_list] + \
                           [f.hstring for f in self.format_list] + \
                           ['\t'.join([
                               '#CHROM',
                               'POS',
                               'ID',
                               'REF',
                               'ALT',
                               'QUAL',
                               'FILTER',
                               'INFO',
                               'FORMAT'] + \
                                      self.sample_list
                                  )])
        return header

    def add_info(self, id, number, type, desc):
        if id not in [i.id for i in self.info_list]:
            inf = self.Info(id, number, type, desc)
            self.info_list.append(inf)

    def add_alt(self, id, desc):
        if id not in [a.id for a in self.alt_list]:
            alt = self.Alt(id, desc)
            self.alt_list.append(alt)

    def add_format(self, id, number, type, desc):
        if id not in [f.id for f in self.format_list]:
            fmt = self.Format(id, number, type, desc)
            self.format_list.append(fmt)

    def add_sample(self, name):
        self.sample_list.append(name)

    class Info(object):
        def __init__(self, id, number, type, desc):
            self.id = str(id)
            self.number = str(number)
            self.type = str(type)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##INFO=<ID=' + self.id + ',Number=' + self.number + ',Type=' + self.type + ',Description=\"' + self.desc + '\">'

    class Alt(object):
        def __init__(self, id, desc):
            self.id = str(id)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##ALT=<ID=' + self.id + ',Description=\"' + self.desc + '\">'

    class Format(object):
        def __init__(self, id, number, type, desc):
            self.id = str(id)
            self.number = str(number)
            self.type = str(type)
            self.desc = str(desc)
            # strip the double quotes around the string if present
            if self.desc.startswith('"') and self.desc.endswith('"'):
                self.desc = self.desc[1:-1]
            self.hstring = '##FORMAT=<ID=' + self.id + ',Number=' + self.number + ',Type=' + self.type + ',Description=\"' + self.desc + '\">'

class Variant(object):
    def __init__(self, var_list, vcf):
        self.chrom = var_list[0]
        self.pos = int(var_list[1])
        self.var_id = var_list[2]
        self.ref = var_list[3]
        self.alt = var_list[4]
        self.qual = float(var_list[5])
        self.filter = var_list[6]
        self.sample_list = vcf.sample_list
        self.info_list = vcf.info_list
        self.info = dict()
        self.format_list = vcf.format_list
        self.active_formats = list()
        self.gts = dict()
        # make a genotype for each sample at variant
        for i in xrange(len(self.sample_list)):
            s_gt = var_list[9+i].split(':')[0]
            s = self.sample_list[i]
            self.gts[s] = Genotype(self, s, s_gt)
        # import the existing fmt fields
        for i in xrange(len(self.sample_list)):
            s = self.sample_list[i]
            for j in zip(var_list[8].split(':'), var_list[9+i].split(':')):
                self.gts[s].set_format(j[0], j[1])

        self.info = dict()
        i_split = [a.split('=') for a in var_list[7].split(';')] # temp list of split info column
        for i in i_split:
            if len(i) == 1:
                i.append(True)
            self.info[i[0]] = i[1]

    def set_info(self, field, value):
        if field in [i.id for i in self.info_list]:
            self.info[field] = value
        else:
            sys.stderr.write('\nError: invalid INFO field, \"' + field + '\"\n')
            exit(1)

    def get_info(self, field):
        return self.info[field]

    def get_info_string(self):
        i_list = list()
        for info_field in self.info_list:
            if info_field.id in self.info.keys():
                if info_field.type == 'Flag':
                    i_list.append(info_field.id)
                else:
                    i_list.append('%s=%s' % (info_field.id, self.info[info_field.id]))
        return ';'.join(i_list)

    def get_format_string(self):
        f_list = list()
        for f in self.format_list:
            if f.id in self.active_formats:
                f_list.append(f.id)
        return ':'.join(f_list)

    def genotype(self, sample_name):
        if sample_name in self.sample_list:
            return self.gts[sample_name]
        else:
            sys.stderr.write('\nError: invalid sample name, \"' + sample_name + '\"\n')

    def get_var_string(self):
        s = '\t'.join(map(str,[
            self.chrom,
            self.pos,
            self.var_id,
            self.ref,
            self.alt,
            '%0.2f' % self.qual,
            self.filter,
            self.get_info_string(),
            self.get_format_string(),
            '\t'.join(self.genotype(s).get_gt_string() for s in self.sample_list)
        ]))
        return s

class Genotype(object):
    def __init__(self, variant, sample_name, gt):
        self.format = dict()
        self.variant = variant
        self.set_format('GT', gt)

    def set_format(self, field, value):
        if field in [i.id for i in self.variant.format_list]:
            self.format[field] = value
            if field not in self.variant.active_formats:
                self.variant.active_formats.append(field)
                # sort it to be in the same order as the format_list in header
                self.variant.active_formats.sort(key=lambda x: [f.id for f in self.variant.format_list].index(x))
        else:
            sys.stderr.write('\nError: invalid FORMAT field, \"' + field + '\"\n')
            exit(1)

    def get_format(self, field):
        return self.format[field]

    def get_gt_string(self):
        g_list = list()
        for f in self.variant.active_formats:
            if f in self.format:
                if type(self.format[f]) == float:
                    g_list.append('%0.2f' % self.format[f])
                else:
                    g_list.append(self.format[f])
            else:
                g_list.append('.')
        return ':'.join(map(str,g_list))

class Bed(object):
    def __init__(self, bedList):
        self.chrom = bedList[0]
        self.start = int(bedList[1])
        self.end = int(bedList[2])
        if len(bedList) > 4:
            self.misc = bedList[3:]

# efficient combinatorial function to handle extremely large numbers
def log_choose(n, k):
    r = 0.0
    # swap for efficiency if k is more than half of n
    if k * 2 > n:
        k = n - k

    for  d in xrange(1,k+1):
        r += math.log(n, 10)
        r -= math.log(d, 10)
        n -= 1

    return r

# return the genotype and log10 p-value
def bayes_gt(ref, alt):
    # probability of seeing an alt read with true genotype of of hom_ref, het, hom_alt respectively
    p_alt = [0.1, 0.4, 0.8]

    total = ref + alt
    
    lp_homref = log_choose(total, alt) + alt * math.log(p_alt[0], 10) + ref * math.log(1 - p_alt[0], 10)
    lp_het = log_choose(total, alt) + alt * math.log(p_alt[1], 10) + ref * math.log(1 - p_alt[1], 10)
    lp_homalt = log_choose(total, alt) + alt * math.log(p_alt[2], 10) + ref * math.log(1 - p_alt[2], 10)

    return (lp_homref, lp_het, lp_homalt)

# return the 5' alignment coordinate of the mate read by parsing the MC (mate cigar) SAM field
def get_mate_5prime(bam, read):
    # if 'MC' in [t[0] for t in read.tags]:
    try:
        p = read.pnext
        mc = read.opt('MC') # the mate CIGAR string
        if mc == '*':
            return
        keys = re.findall('[MIDNSHPX=]+', mc)
        nums = map(int, re.findall('[^MIDNSHPX=]+', mc))

        for i in xrange(len(keys)):
            k = keys[i]
            n = nums[i]
            if k == 'M' or k == 'N' or k == 'D':
                p += n
            # if k == 'I' or k == 'P' or k == 'S' or k == 'H':
            #     pass
    except KeyError:
        p = bam.mate(read).aend
    return p

# calculate the probability that a read is concordant at a deletion breakpoint,
# given the putative deletion size and insert distribution of the library.
def p_concordant(read_ospan, var_length, mean_ospan, sd_ospan):
    conc_z = (read_ospan - mean_ospan) / sd_ospan
    p = 1 - norm.cdf(conc_z)

    disc_z = (read_ospan - var_length - mean_ospan) / sd_ospan
    q = norm.cdf(disc_z)

    if p + q == 0:
        return 0
    else:
        return p / (p + q)

def count_pairedend(chrom, pos, mate_chrom, mate_pos, o1, o2, mean_ospan, sd_ospan, z, discflank, read_length, mybam):
    conc_counter = 0
    disc_counter = 0

    if o1 == '+':
        # survey for concordant read pairs
        for read in mybam.fetch(chrom, pos - (mean_ospan + sd_ospan * z), pos):
            # get the mate mapping quality if available, otherwise set to 60 (perfect mapping)
            try:
                mate_mapq = float(read.opt('MQ')) # mate mapping quality
            except KeyError:
                mate_mapq = 60.0

            if read.is_reverse or not read.mate_is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.pos + discflank > pos or read.pnext + read_length - discflank < pos or read.tid != read.rnext:
                continue
            else:
                ospan = get_mate_5prime(mybam, read) - read.pos
                prob_conc = p_concordant(ospan, abs(mate_pos - pos), mean_ospan, sd_ospan)

                ispan1 = read.pos + discflank
                ispan2 = get_mate_5prime(mybam, read) - discflank - 1
                ispan = ispan2 - ispan1

                if ispan2 > pos:
                    conc_counter += prob_conc * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                    if o2 == '-' and chrom == mate_chrom and pos < mate_pos:
                        disc_counter += (1 - prob_conc) * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                        continue

        # survey for discordant pairs
        for read in mybam.fetch(chrom, pos - (mean_ospan + sd_ospan * z), pos):
            # get the mate mapping quality if available, otherwise set to 60 (perfect mapping)
            try:
                mate_mapq = float(read.opt('MQ')) # mate mapping quality
            except KeyError:
                mate_mapq = 60.0

            if read.is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.pnext + read_length - discflank < pos:
                continue

            # +/- but other than deletion
            elif o2 == '-' and not (chrom == mate_chrom and pos < mate_pos):
                if not read.mate_is_reverse or read.pnext + read_length - discflank < pos:
                    continue
                else:
                    ospan = get_mate_5prime(mybam, read) - read.pos
                    prob_conc = p_concordant(ospan, abs(mate_pos - pos), mean_ospan, sd_ospan)

                    ispan1 = read.pos + discflank
                    ispan2 = get_mate_5prime(mybam, read) - discflank - 1
                    ispan = ispan2 - ispan1

                    disc_counter += (1 - prob_conc) * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
            # +/- translocation
            elif o2 == '-' and chrom != mate_chrom:
                if not read.mate_is_reverse or read.pnext + read_length - discflank < pos:
                    continue
                else:
                    disc_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
            # +/+ inversion
            elif o2 == '+':
                if not read.mate_is_reverse:
                    disc_counter += 1-10**(-read.mapq/10.0) * (1-10**(-mate_mapq/10.0))
    elif o1 == '-':
        # survey for concordant read pairs
        for read in mybam.fetch(chrom, pos, pos + (mean_ospan + sd_ospan * z)):
            # get the mate mapping quality if available, otherwise set to 60 (perfect mapping)
            try:
                mate_mapq = float(read.opt('MQ')) # mate mapping quality
            except KeyError:
                mate_mapq = 60.0

            if not read.is_reverse or read.mate_is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.aend - discflank < pos or read.pnext + discflank > pos or read.tid != read.rnext:
                continue
            else:
                ospan = read.aend - read.pnext
                prob_conc = p_concordant(ospan, abs(mate_pos - pos), mean_ospan, sd_ospan)

                ispan1 = read.pnext + discflank
                ispan2 = read.aend - discflank - 1
                ispan = ispan2 - ispan1

                if ispan1 < pos:
                    conc_counter += prob_conc * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                    if o2 == '+' and chrom == mate_chrom and mate_pos < pos:
                        disc_counter += (1 - prob_conc) * (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))
                        continue

        # survey for discordant read pairs
        for read in mybam.fetch(chrom, pos, pos + (mean_ospan + sd_ospan * z)):
            # get the mate mapping quality if available, otherwise set to 60 (perfect mapping)
            try:
                mate_mapq = float(read.opt('MQ')) # mate mapping quality
            except KeyError:
                mate_mapq = 60.0

            if not read.is_reverse or read.is_secondary or read.is_unmapped or read.mate_is_unmapped or read.is_duplicate or read.pnext + read_length - discflank > pos:
                continue

            # -/+ tandem duplication (or interchromosomal)
            elif o2 == '+':
                if not read.mate_is_reverse and not (chrom == mate_chrom and mate_pos < pos):
                    disc_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))

            # -/- inversion
            elif o2 == '-':
                if read.mate_is_reverse:
                    disc_counter += (1-10**(-read.mapq/10.0)) * (1-10**(-mate_mapq/10.0))

    return (conc_counter, disc_counter)

def insert_dist(bam):
    num_samp = 1000000
    counter = 0
    skip = 5000000
    skip_counter = 0
    ins_list = []
    for read in bam.fetch():
        if skip_counter < skip:
            skip_counter += 1
            continue
        if read.is_proper_pair and not read.is_reverse and not read.is_secondary:
            ins_list.append(read.tlen)
            counter += 1
        if counter == num_samp:
            break
    mean = sum(ins_list)/float(len(ins_list))
    v = 0
    for i in ins_list:
        v += (i-mean)**2
    variance = v/float(len(ins_list))
    stdev = variance**(0.5)
    return (mean, stdev)

def get_read_length(bam):
    max_rl = 0
    counter = 0
    num_samp = 10000
    for read in bam.fetch():
        if read.qlen > max_rl:
            max_rl = read.qlen
        if counter == num_samp:
            break
        counter += 1
    return max_rl
        

# primary function
def sv_genotype(vcf_file, bam, spl_bam, vcf_out, splflank, discflank, mean_ospan, sd_ospan, read_length, split_weight, disc_weight, debug):
    # sample insert size distribution
    if mean_ospan == None or sd_ospan == None:
        (mean_ospan, sd_ospan) = insert_dist(bam)

    # get read length if not specified.
    if read_length == None:
        read_length = get_read_length(bam)

    z = 3
    padding = 30
    in_header = True
    header = []
    breakend_dict = {} # cache to hold unmatched generic breakends for genotyping
    vcf = Vcf()

    # first get the sample name from the bam file
    sample = bam.header['RG'][0]['SM']

    mean_ispan = mean_ospan - (2 * discflank)
    sd_ispan = sd_ospan

    for line in vcf_file:
        if in_header:
            if line[0] == '#':
                header.append(line) 
                if line[1] != '#':
                    vcf_samples = line.rstrip().split('\t')[9:]
                continue
            else:
                in_header = False
                vcf.add_header(header)
                vcf.add_format('RO', 1, 'Integer', 'Reference allele observation count, with partial observations recorded fractionally')
                vcf.add_format('AO', 'A', 'Integer', 'Alternate allele observations, with partial observations recorded fractionally')
                vcf_out.write(vcf.get_header() + '\n')

        v = line.rstrip().split('\t')
        var = Variant(v, vcf)

        # genotype generic breakends
        if var.info['SVTYPE']=='BND':
            if var.info['MATEID'] in breakend_dict:
                if 'PRIN' in breakend_dict[var.info['MATEID']].info:
                    var2 = var
                    var = breakend_dict[var.info['MATEID']]
                    chromA = var.chrom
                    chromB = var2.chrom
                    posA = var.pos
                    # SHOULD NOT ADD 1 HERE, CURRENTLY ADJUSTING FOR A LUMPY OFF-BY-ONE ERROR
                    posB = var2.pos + 1

                    # infer the strands from the alt allele
                    if var.alt[-1] == '[' or var.alt[-1] == ']':
                        o1 = '+'
                    else: o1 = '-'
                    if var2.alt[-1] == '[' or var2.alt[-1] == ']':
                        o2 = '+'
                    else: o2 = '-'
                elif 'PRIN' in var.info:
                    var2 = breakend_dict[var.info['MATEID']]
                    chromA = var.chrom
                    chromB = var2.chrom
                    posA = var.pos
                    # SHOULD NOT ADD 1 HERE, CURRENTLY ADJUSTING FOR A LUMPY OFF-BY-ONE ERROR
                    posB = var2.pos + 1
                    
                    # infer the strands from the alt allele
                    if var.alt[-1] == '[' or var.alt[-1] == ']':
                        o1 = '+'
                    else: o1 = '-'
                    if var2.alt[-1] == '[' or var2.alt[-1] == ']':
                        o2 = '+'
                    else: o2 = '-'
            else:
                breakend_dict[var.var_id] = var
                continue

            # write out and skip
            # vcf_out.write(var.get_var_string() + '\n')
            # continue
        else:
            chromA = var.chrom
            chromB = var.chrom
            posA = var.pos
            # SHOULD NOT ADD 1 HERE, CURRENTLY ADJUSTING FOR A LUMPY OFF-BY-ONE ERROR
            posB = int(var.get_info('END')) + 1
            o1, o2 =  list(var.get_info('STR').split(',')[0].split(':')[0])

        '''
        Breakend A
        '''
        # Count splitters
        ref_counter_a = Counter()
        spl_counter_a = Counter()
        for ref_read in bam.fetch(chromA, posA - padding, posA + padding + 1):
            if not ref_read.is_duplicate and not ref_read.is_unmapped:
                for p in xrange(ref_read.pos + 1, ref_read.aend + 1):
                    if p - ref_read.pos >= splflank and ref_read.aend - p >= splflank:
                        ref_counter_a[p] += (1-10**(-ref_read.mapq/10.0))
        for spl_read in spl_bam.fetch(chromA, posA - padding, posA + padding + 1):
            if not spl_read.is_duplicate and not spl_read.is_unmapped:
                if o1 == '+' and spl_read.cigar[0][0] == 0:
                    spl_counter_a[spl_read.aend] += (1-10**(-spl_read.mapq/10.0))
                elif o1 == '-' and spl_read.cigar[-1][0] == 0:
                    spl_counter_a[spl_read.pos + 1] += (1-10**(-spl_read.mapq/10.0))

        # Count paired-end discordant and concordants
        (conc_counter_a, disc_counter_a) = count_pairedend(chromA, posA, chromB, posB, o1, o2, mean_ospan, sd_ospan, z, discflank, read_length, bam)

        '''
        Breakend B
        '''
        # Count splitters
        ref_counter_b = Counter()
        spl_counter_b = Counter()
        for ref_read in bam.fetch(chromB, posB - padding, posB + padding + 1):
            if not ref_read.is_duplicate and not ref_read.is_unmapped:
                for p in xrange(ref_read.pos + 1, ref_read.aend + 1):
                    if p - ref_read.pos >= splflank and ref_read.aend - p >= splflank:
                        ref_counter_b[p] += (1-10**(-ref_read.mapq/10.0))
        for spl_read in spl_bam.fetch(chromB, posB - padding, posB + padding + 1):
            if not spl_read.is_duplicate and not spl_read.is_unmapped:
                if o2 == '+' and spl_read.cigar[0][0] == 0:
                    spl_counter_b[spl_read.aend] += (1-10**(-spl_read.mapq/10.0))
                elif o2 == '-' and spl_read.cigar[-1][0] == 0:
                    spl_counter_b[spl_read.pos] += (1-10**(-spl_read.mapq/10.0))

        # Count paired-end discordants and concordants
        (conc_counter_b, disc_counter_b) = count_pairedend(chromB, posB, chromA, posA, o2, o1, mean_ospan, sd_ospan, z, discflank, read_length, bam)

        if debug:
            print 'sr_a', ref_counter_a[posA], spl_counter_a[posA]
            print 'pe_a', conc_counter_a, disc_counter_a
            print 'sr_b', ref_counter_b[posB], spl_counter_b[posB]
            print 'pe_b', conc_counter_b, disc_counter_b


        # if there are informative reads at the site, output inferred genotype
        if len(spl_counter_a) + len(spl_counter_b) + disc_counter_a + disc_counter_b > 0:
            split_ref = int(split_weight * (ref_counter_a[posA] + ref_counter_b[posB]))
            split_alt = int(split_weight * (spl_counter_a[posA] + spl_counter_b[posB]))
            disc_ref = int(disc_weight * (conc_counter_a + conc_counter_b))
            disc_alt = int(disc_weight * (disc_counter_a + disc_counter_b))

            # get bayesian classifier
            gt_lplist = bayes_gt(split_ref + disc_ref, split_alt + disc_alt)
            gt_idx = gt_lplist.index(max(gt_lplist[1:]))

            # print log probabilities of homref, het, homalt
            if debug:
                print gt_lplist

            # set the overall variant QUAL score and sample specific fields
            var.qual = -10 * (gt_lplist[0] - sum(10**x for x in gt_lplist))
            var.genotype(sample).set_format('GQ', -10 * (gt_lplist[0] - sum(10**x for x in gt_lplist)))
            var.genotype(sample).set_format('DP', spl_counter_a[posA] + ref_counter_a[posA] + spl_counter_b[posB] + ref_counter_b[posB] + conc_counter_a + disc_counter_a + conc_counter_b + disc_counter_b)
            var.genotype(sample).set_format('AO', spl_counter_a[posA] + spl_counter_b[posB] + disc_counter_a + disc_counter_b)
            var.genotype(sample).set_format('RO', ref_counter_a[posA] + ref_counter_b[posB] + conc_counter_a + conc_counter_b)

            # don't genotype if LUMPY call is reference
            if var.genotype(sample).get_format('GT') == '0/0':
                vcf_out.write(var.get_var_string() + '\n')
                continue
            if gt_idx == 1:
                var.genotype(sample).set_format('GT', '0/1')
            elif gt_idx == 2:
                var.genotype(sample).set_format('GT', '1/1')
        else:
            var.genotype(sample).set_format('GT', './.')
            var.qual = 0

        vcf_out.write(var.get_var_string() + '\n')
        if var.info['SVTYPE'] == 'BND':
            var2.qual = var.qual
            var2.active_formats = var.active_formats
            var2.genotype = var.genotype
            vcf_out.write(var2.get_var_string() + '\n')
    vcf_out.close()
    
    return

# --------------------------------------
# main function

def main():
    # parse the command line args
    args = get_args()

    # call primary function
    sv_genotype(args.input_vcf, args.bam, args.split_bam, args.output_vcf, args.splflank, args.discflank, args.mean_frag_size, args.sd_frag_size, args.read_length, args.split_weight, args.disc_weight, args.debug)

    # close the files
    args.input_vcf.close()

# initialize the script
if __name__ == '__main__':
    try:
        sys.exit(main())
    except IOError, e:
        if e.errno != 32:  # ignore SIGPIPE
            raise 
